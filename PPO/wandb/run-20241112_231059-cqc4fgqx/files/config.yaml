wandb_version: 1

dataset_path:
  desc: null
  value: trl-internal-testing/tldr-preference-sft-trl-style
model_path:
  desc: null
  value: meta-llama/Llama-3.2-1B-Instruct
sft_model_name:
  desc: null
  value: meta-llama/Llama-3.2-1B-Instruct
reward_model_name:
  desc: null
  value: meta-llama/Llama-3.2-1B-Instruct
per_device_train_batch_size:
  desc: null
  value: 3
gradient_accumulation_steps:
  desc: null
  value: 4
learning_rate:
  desc: null
  value: 2.0e-05
weight_decay:
  desc: null
  value: 0.001
gradient_checkpointing:
  desc: null
  value: true
max_seq_length:
  desc: null
  value: 2048
freeze_embed:
  desc: null
  value: false
bf16:
  desc: null
  value: true
lr_scheduler_type:
  desc: null
  value: cosine
use_lora:
  desc: null
  value: false
max_steps:
  desc: null
  value: -1
num_train_epochs:
  desc: null
  value: 3
_wandb:
  desc: null
  value:
    code_path: code/PPO/PPO.py
    python_version: 3.10.12
    cli_version: 0.16.5
    framework: huggingface
    huggingface_version: 4.46.2
    is_jupyter_run: false
    is_kaggle_kernel: false
    start_time: 1731453060.0
    t:
      1:
      - 1
      - 5
      - 11
      - 41
      - 49
      - 51
      - 53
      - 55
      - 71
      - 84
      - 98
      2:
      - 1
      - 5
      - 11
      - 41
      - 49
      - 51
      - 53
      - 55
      - 71
      - 84
      - 98
      3:
      - 15
      - 16
      - 23
      4: 3.10.12
      5: 0.16.5
      6: 4.46.2
      8:
      - 5
      13: linux-x86_64
