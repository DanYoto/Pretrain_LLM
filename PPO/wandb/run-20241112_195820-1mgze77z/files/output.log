Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-3.2-1B-Instruct and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-3.2-1B-Instruct and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.










Map (num_proc=4): 100%|█████████████████████████████████████████████████████████████████| 116722/116722 [00:21<00:00, 5471.87 examples/s]
Traceback (most recent call last):
  File "/mnt/batch/tasks/shared/LS_root/mounts/clusters/yutong-8gpus-training/code/Users/yutong.jiang2/Pretrain_LLM/PPO/PPO.py", line 36, in <module>
    trainer = PPOTrainer(
  File "/home/azureuser/.pyenv/versions/3.10.12/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py", line 139, in __init__
    if args.total_episodes is None:  # allow the users to define episodes in terms of epochs.
AttributeError: 'TrainingArguments' object has no attribute 'total_episodes'